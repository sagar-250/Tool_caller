{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import initialize_agent,AgentType\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# from langchain.chains import SequentialChain\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"GROQ_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools1=[\n",
    "  {\n",
    "      \"tool_name\": \"who_am_i\",\n",
    "      \"tool_description\": \"Returns the id of the current user\",\n",
    "      \"args\": [],\n",
    "      \"output\": {\n",
    "          \"arg_type\": \"str\",\n",
    "          \"is_array\": False,\n",
    "          \"is_required\": True\n",
    "      }\n",
    "  },\n",
    "  {\n",
    "      \"tool_name\": \"get_sprint_id\",\n",
    "      \"tool_description\": \"Returns the ID\\nof the current\\nsprint\",\n",
    "      \"args\": [],\n",
    "      \"output\": {\n",
    "          \"arg_type\": \"str\",\n",
    "          \"is_array\": False,\n",
    "          \"is_required\": True\n",
    "      }\n",
    "  },\n",
    "  {\n",
    "    \"tool_name\": \"works_list\",\n",
    "    \"tool_description\": \"Returns a list of work items matching the request\",\n",
    "    \"args\": [\n",
    "    {\n",
    "    \"arg_name\": \"applies_to_part\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"created_by\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"issue_priority\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"issue.rev_orgs\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"limit\",\n",
    "    \"arg_type\": \"int\",\n",
    "    \"is_array\": False,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"owned_by\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"stage_name\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"ticket_need_response\",\n",
    "    \"arg_type\": \"boolean\",\n",
    "    \"is_array\": False,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"ticket_rev_org\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"ticket_severity\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"ticket_source_channel\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    },\n",
    "    {\n",
    "    \"arg_name\": \"type\",\n",
    "    \"arg_type\": \"str\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": False\n",
    "    }\n",
    "    ],\n",
    "    \"output\": {\n",
    "    \"arg_type\": \"any\",\n",
    "    \"is_array\": False,\n",
    "    \"is_required\": True\n",
    "    }\n",
    "    },\n",
    "    {\n",
    "    \"tool_name\": \"summarize_objects\",\n",
    "    \"tool_description\": \"Summarizes a list of objects. The logic of how to summarize a particular object type is an internal implementation detail.\",\n",
    "    \"args\": [\n",
    "    {\n",
    "    \"arg_name\": \"objects\",\n",
    "    \"arg_type\": \"any\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": True\n",
    "    }\n",
    "    ],\n",
    "    \"output\": {\n",
    "    \"arg_type\": \"any\",\n",
    "    \"is_array\": False,\n",
    "    \"is_required\": True\n",
    "    }\n",
    "    },\n",
    "    {\n",
    "    \"tool_name\": \"prioritize_objects\",\n",
    "    \"tool_description\": \"Returns a list of objects sorted by priority. The logic of what constitutes priority for a given object is an internal implementation detail\",\n",
    "    \"args\": [\n",
    "    {\n",
    "    \"arg_name\": \"objects\",\n",
    "    \"arg_type\": \"any\",\n",
    "    \"is_array\": False,\n",
    "    \"is_required\": False\n",
    "    }\n",
    "    ],\n",
    "    \"output\": {\n",
    "    \"arg_type\": \"any\",\n",
    "    \"is_array\": True,\n",
    "    \"is_required\": True\n",
    "    }\n",
    "}]\n",
    "\n",
    "# llm = ChatGroq(\n",
    "# model=\"llama-3.1-8b-instant\",\n",
    "# temperature=0.3,\n",
    "# max_tokens=None,\n",
    "# timeout=None,\n",
    "# max_retries=2,\n",
    "# tools=tools,\n",
    "# tool_choice=\"auto\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from groq import Groq\n",
    "import os\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"tool_name\":\"works_list\",\"arguments\":[{\"argument_name\":\"ticket_source_channel\",\"argument_value\":[\"support\"]}]}',\n",
       " '{\"tool_name\":\"summarize_objects\",\"arguments\":[{\"argument_name\":\"objects\",\"argument_value\":[\"$$PREV[0]\"]}]}']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class Argument(BaseModel):\n",
    "    argument_name: str\n",
    "    argument_value: List[str]\n",
    "\n",
    "class Tool(BaseModel):\n",
    "    tool_name: str\n",
    "    arguments: List[Argument]\n",
    "    \n",
    "class ResponseModel(BaseModel):\n",
    "    tool_calls: list[Tool]\n",
    "    \n",
    "client = instructor.from_groq(Groq(), mode=instructor.Mode.JSON) \n",
    "\n",
    "def run_conversation(user_prompt,tools):\n",
    "    tools=tools\n",
    "    # Prepare the messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"You are an assistant that can use tools. You have access to the following tool: {tools}.go through each argument provided properly and ive every needed arg\n",
    "            when you need output from of i th previous tool for argument write \"$$PREV[i]\" in the argument .order the function calling properly for the task.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Make the Groq API call\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "        response_model=ResponseModel,\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "\n",
    "    return response.tool_calls\n",
    "\n",
    "# Example usage\n",
    "\n",
    "def output(query,tools):\n",
    "    tool_calls = run_conversation(query,tools)\n",
    "    # print(tool_calls)\n",
    "    \n",
    "    output=[] \n",
    "    for i in tool_calls:\n",
    "        output.append(i.json())\n",
    "        \n",
    "    return output    \n",
    "\n",
    "user_prompt=\"Summarize tickets from ’support’ channel\"   \n",
    "output(user_prompt,tools1)    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATIVITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
